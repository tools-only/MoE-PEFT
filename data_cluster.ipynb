{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89675c81",
   "metadata": {},
   "source": [
    "Load user preference data and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020fb15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "features_persona = [\n",
    "    (\"Young\", \"Older\"),\n",
    "    (\"Female\", \"Male\"),\n",
    "    (\"High Neuroticism\", \"Low Neuroticism\"),\n",
    "    (\"High Extraversion\", \"Low Extraversion\"),\n",
    "    (\"High Openness\", \"Low Openness\"),\n",
    "    (\"High Agreeableness\", \"Low Agreeableness\"),\n",
    "    (\"High Conscientiousness\", \"Low Conscientiousness\"),\n",
    "    (\"Likes a certain food\", \"Dislikes a certain food\"),\n",
    "    (\"Likes a certain living environment\", \"Dislikes a certain living environment\"),\n",
    "    (\"Likes sleep\", \"Dislikes sleep\"),\n",
    "    (\"Aggressive investment\", \"Conservative investment\"),\n",
    "    (\"Good at saving\", \"Bad at saving\"),\n",
    "    (\"Concerned about physical safety\", \"Not concerned about physical safety\"),\n",
    "    (\"Concerned about environmental safety\", \"Not concerned about environmental safety\"),\n",
    "    (\"Prefers superficial interaction\", \"Prefers deep interaction\"),\n",
    "    (\"Prefers direct communication to handle conflict\", \"Prefers avoidance, mediation, compromise to handle conflict\"),\n",
    "    (\"Concise communication style\", \"Detailed communication style\"),\n",
    "    (\"Strong need for a certain work environment\", \"Indifferent to work environment needs\"),\n",
    "    (\"Strong need for recognition from others\", \"Indifferent to recognition from others\"),\n",
    "    (\"Strong need for personal achievement\", \"Indifferent to personal achievement\"),\n",
    "    (\"Likes a certain area of knowledge\", \"Dislikes a certain area of knowledge\"),\n",
    "    (\"Likes a certain learning style\", \"Dislikes a certain learning style\"),\n",
    "    (\"Likes a certain form of creative expression\", \"Dislikes a certain form of creative expression\"),\n",
    "    (\"Strong need for Order\", \"Indifferent to orderliness\"),\n",
    "    (\"Strong need for Retention\", \"Indifferent to retention\"),\n",
    "    (\"Strong need for Inviolacy\", \"Indifferent to inviolacy\"),\n",
    "    (\"Strong need for Infavoidance\", \"Indifferent to Infavoidance\"),\n",
    "    (\"Strong need for Counteraction\", \"Indifferent to Counteraction\"),\n",
    "    (\"Strong need for Seclusion\", \"Indifferent to Seclusion\"),\n",
    "    (\"Strong need for Dominance\", \"Indifferent to Dominance\"),\n",
    "    (\"Strong need for Deference\", \"Indifferent to Deference\"),\n",
    "    (\"Strong need for Autonomy\", \"Indifferent to Autonomy\"),\n",
    "    (\"Strong need for Contrariance\", \"Indifferent to Contrariance\"),\n",
    "    (\"Strong need for Abasement\", \"Indifferent to Abasement\"),\n",
    "    (\"Strong need for Aggression\", \"Indifferent to Aggression\"),\n",
    "    (\"Strong need for Affiliation\", \"Indifferent to Affiliation\"),\n",
    "    (\"Strong need for Rejection\", \"Indifferent to Rejection\"),\n",
    "    (\"Strong need for Nurturance\", \"Indifferent to Nurturance\"),\n",
    "    (\"Strong need for Succorance\", \"Indifferent to Succorance\"),\n",
    "    (\"Strong need for Play\", \"Indifferent to Play\"),\n",
    "    (\"Concerned about harmlessness\", \"Indifferent about harmlessness\"),\n",
    "    (\"Concerned about instruction-following\", \"Indifferent about instruction-following\"),\n",
    "    (\"Concerned about honesty\", \"Indifferent about honesty\"),\n",
    "    (\"Concerned about truthfulness\", \"Indifferent about truthfulness\"),\n",
    "    (\"Concerned about helpfulness\", \"Indifferent about helpfulness\"),\n",
    "    (\"Concerned about coherence\", \"Indifferent about coherence\"),\n",
    "    (\"Concerned about complexity\", \"Indifferent about complexity\"),\n",
    "    (\"Likes science\", \"Dislikes science\"),\n",
    "    (\"Likes knowledge\", \"Dislikes knowledge\"),\n",
    "    (\"Likes psychology\", \"Dislikes psychology\"),\n",
    "    (\"Likes cinema\", \"Dislikes cinema\"),\n",
    "    (\"Likes entertainment\", \"Dislikes entertainment\"),\n",
    "    (\"Likes gaming\", \"Dislikes gaming\"),\n",
    "    (\"Likes parenting\", \"Dislikes parenting\"),\n",
    "    (\"Likes wild imagination\", \"Dislikes wild imagination\"),\n",
    "    (\"Likes anime\", \"Dislikes anime\"),\n",
    "    (\"Likes sports\", \"Dislikes sports\"),\n",
    "    (\"Likes law\", \"Dislikes law\"),\n",
    "    (\"Likes workplace\", \"Dislikes workplace\"),\n",
    "    (\"Likes pets\", \"Dislikes pets\"),\n",
    "    (\"Likes travel\", \"Dislikes travel\"),\n",
    "    (\"Likes health\", \"Dislikes health\"),\n",
    "    (\"Likes stories\", \"Dislikes stories\"),\n",
    "    (\"Likes cars\", \"Dislikes cars\"),\n",
    "    (\"Likes gourmet food\", \"Dislikes gourmet food\"),\n",
    "    (\"Likes education\", \"Dislikes education\"),\n",
    "    (\"Likes current events\", \"Dislikes current events\"),\n",
    "    (\"Likes home decor\", \"Dislikes home decor\"),\n",
    "    (\"Likes international\", \"Dislikes international\"),\n",
    "    (\"Likes finance\", \"Dislikes finance\"),\n",
    "    (\"Likes campus life\", \"Dislikes campus life\"),\n",
    "    (\"Likes digital technology\", \"Dislikes digital technology\"),\n",
    "    (\"Likes emotions\", \"Dislikes emotions\"),\n",
    "    (\"Likes humor\", \"Dislikes humor\"),\n",
    "    (\"Likes music\", \"Dislikes music\"),\n",
    "    (\"Likes reading\", \"Dislikes reading\"),\n",
    "    (\"Likes painting\", \"Dislikes painting\"),\n",
    "    (\"Likes dance\", \"Dislikes dance\"),\n",
    "    (\"Likes crafts\", \"Dislikes crafts\"),\n",
    "    (\"Likes photography\", \"Dislikes photography\"),\n",
    "    (\"Likes culture\", \"Dislikes culture\"),\n",
    "    (\"Likes fitness\", \"Dislikes fitness\"),\n",
    "    (\"Likes art\", \"Dislikes art\"),\n",
    "    (\"Likes stationery and planners\", \"Dislikes stationery and planners\"),\n",
    "    (\"Likes celebrities\", \"Dislikes celebrities\"),\n",
    "    (\"Likes outdoors\", \"Dislikes outdoors\"),\n",
    "    (\"Likes camping\", \"Dislikes camping\"),\n",
    "    (\"Likes social sciences\", \"Dislikes social sciences\"),\n",
    "    (\"Likes weddings\", \"Dislikes weddings\"),\n",
    "    (\"Likes fashion\", \"Dislikes fashion\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180e9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/data1/zq/alignX.json'\n",
    "file_path = '/data1/zq/AlignX/train.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)  # 使用 json.load() 读取文件内容并解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6120a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_NUM = 50\n",
    "\n",
    "pattern = \"Generate a task-specific response based on user historical behavior.\\n\\n***Task***\\n\\n\"\n",
    "\n",
    "def get_preference_text(direction, value):\n",
    "    if direction < 0 or direction >= len(features_persona):\n",
    "        raise ValueError(\"preference_direction 超出范围！\")\n",
    "    option_pair = features_persona[direction]\n",
    "    selected_text = option_pair[0] if value == 1 else option_pair[1]\n",
    "    return f\"{selected_text}\"  # 用 f-string 添加方括号\n",
    "\n",
    "def create_preference_vector(direction):\n",
    "    vector = [0] * 90\n",
    "    vector[direction] = 1\n",
    "    return vector\n",
    "\n",
    "training_groups = {}\n",
    "records = []\n",
    "\n",
    "def is_duplicate(record, records_list):\n",
    "    \"\"\"检查当前记录是否已经存在于records中（基于prefix/prompt/chosen/rejected）\"\"\"\n",
    "    for existing_record in records_list:\n",
    "        if (existing_record['prefix'] == record['prefix'] and\n",
    "            existing_record['prompt'] == record['prompt'] and\n",
    "            existing_record['chosen'] == record['chosen'] and\n",
    "            existing_record['rejected'] == record['rejected']):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for dimension in range(90):\n",
    "    if dimension not in training_groups:\n",
    "        training_groups[dimension] = {}\n",
    "        training_groups[dimension][0] = []\n",
    "        training_groups[dimension][0.5] = []\n",
    "        training_groups[dimension][1] = []\n",
    "    temp = {}\n",
    "    for user_index, item in enumerate(data):\n",
    "        if len(training_groups[dimension][0]) >= ITEM_NUM and len(training_groups[dimension][1]) >= ITEM_NUM:\n",
    "            break\n",
    "        # 统计current_pairs\n",
    "        for prefer in item['preference_direction']['0']:\n",
    "            if prefer == dimension and len(training_groups[dimension][0]) < ITEM_NUM:\n",
    "                # sft prompt\n",
    "                task = item['instruction'].replace(pattern, '')\n",
    "                persona = ', '.join(item.strip('[]') for item in item['prefix'])\n",
    "                sft_prompt = (\n",
    "                    \"<|start_header_id|>system<|end_header_id|>\\n\\nGenerate a task-specific response based on user preferences.\\n<|eot_id|>\"\n",
    "                    \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "                    f\"***Task***\\n\\n{task}\"\n",
    "                    f\"***User Preferences***\\n\\n{persona}\\n\\n***Response:***\\n\\n<|eot_id|>\"\n",
    "                    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "                )\n",
    "                                \n",
    "                temp['user_index'] = user_index\n",
    "                temp['history_index'] = -1\n",
    "                temp['preference_direction'] = dimension\n",
    "                temp[\"preference_vector\"] = create_preference_vector(temp[\"preference_direction\"])\n",
    "                temp['preference_value'] = 0\n",
    "                temp['preference'] = item['preference']\n",
    "\n",
    "                temp['prefix'] = persona\n",
    "                temp[\"prefix_single\"] = get_preference_text(temp[\"preference_direction\"], temp[\"preference_value\"])\n",
    "                temp['prompt'] = sft_prompt\n",
    "                temp['chosen'] = item['chosen']\n",
    "                temp['rejected'] = item['rejected']\n",
    "                \n",
    "                if not is_duplicate(temp, records):\n",
    "                    training_groups[dimension][0].append(tuple([user_index, -1]))\n",
    "                    records.append(temp.copy())\n",
    "                temp = {}\n",
    "\n",
    "        for prefer in item['preference_direction']['1']:\n",
    "            if prefer == dimension and len(training_groups[dimension][1]) < ITEM_NUM:\n",
    "                # sft prompt\n",
    "                task = item['instruction'].replace(pattern, '')\n",
    "                persona = ', '.join(item.strip('[]') for item in item['prefix'])\n",
    "                sft_prompt = (\n",
    "                    \"<|start_header_id|>system<|end_header_id|>\\n\\nGenerate a task-specific response based on user preferences.\\n<|eot_id|>\"\n",
    "                    \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "                    f\"***Task***\\n\\n{task}\"\n",
    "                    f\"***User Preferences***\\n\\n{persona}\\n\\n***Response:***\\n\\n<|eot_id|>\"\n",
    "                    \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "                )\n",
    "\n",
    "                temp['user_index'] = user_index\n",
    "                temp['history_index'] = -1\n",
    "                temp['preference_direction'] = dimension\n",
    "                temp[\"preference_vector\"] = create_preference_vector(temp[\"preference_direction\"])\n",
    "                temp['preference_value'] = 1\n",
    "                temp['preference'] = item['preference']\n",
    "\n",
    "                temp['prefix'] = persona\n",
    "                temp[\"prefix_single\"] = get_preference_text(temp[\"preference_direction\"], temp[\"preference_value\"])\n",
    "                temp['prompt'] = sft_prompt\n",
    "                temp['chosen'] = item['chosen']\n",
    "                temp['rejected'] = item['rejected']\n",
    "                \n",
    "                if not is_duplicate(temp, records):\n",
    "                    training_groups[dimension][1].append(tuple([user_index, -1]))\n",
    "                    records.append(temp.copy())\n",
    "                temp = {}\n",
    "\n",
    "        # # 统计history_pairs\n",
    "        # for his_index, value in item['history_pairs'].items():\n",
    "        #     prompt = value['prompt']\n",
    "        #     chosen = value['chosen']\n",
    "        #     rejected = value['rejected']\n",
    "        #     preference = value['preference']\n",
    "        #     prefix = value['prefix']\n",
    "        #     for prefer in value['preference_direction']['0']:\n",
    "        #         if prefer == dimension and len(training_groups[dimension][0]) < ITEM_NUM:\n",
    "        #             temp['user_index'] = user_index\n",
    "        #             temp['history_index'] =  int(his_index)\n",
    "        #             temp['preference_direction'] = dimension\n",
    "        #             temp['preference_value'] = 0\n",
    "        #             temp['preference'] = preference\n",
    "        #             temp['prefix'] = prefix\n",
    "        #             temp['prompt'] = prompt\n",
    "        #             temp['chosen'] = chosen\n",
    "        #             temp['rejected'] = rejected\n",
    "\n",
    "        #             if not is_duplicate(temp, records):\n",
    "        #                 training_groups[dimension][0].append((user_index, int(his_index)))\n",
    "        #                 records.append(temp.copy())\n",
    "        #             temp = {}\n",
    "\n",
    "        #     for prefer in value['preference_direction']['1']:\n",
    "        #         if prefer == dimension and len(training_groups[dimension][1]) < ITEM_NUM:\n",
    "        #             temp['user_index'] = user_index\n",
    "        #             temp['history_index'] =  int(his_index)\n",
    "        #             temp['preference_direction'] = dimension\n",
    "        #             temp['preference_value'] = 1\n",
    "        #             temp['preference'] = preference\n",
    "        #             temp['prefix'] = prefix\n",
    "        #             temp['prompt'] = prompt\n",
    "        #             temp['chosen'] = chosen\n",
    "        #             temp['rejected'] = rejected\n",
    "        #             if not is_duplicate(temp, records):\n",
    "        #                 training_groups[dimension][1].append((user_index, int(his_index)))\n",
    "        #                 records.append(temp.copy())\n",
    "        #             temp = {}\n",
    "\n",
    "with open(f'group_records_{len(records)}.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for record in records:\n",
    "        json.dump(record, f, ensure_ascii=False)\n",
    "        f.write('\\n')  # 每行一个JSON对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6946be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/data1/zq/alignX.json'\n",
    "file_path = './group_records_1800.jsonl'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取JSONL文件为DataFrame\n",
    "df = pd.read_json(file_path, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2a2c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Generate a task-specific response based on user preferences.\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "***Task***\n",
      "\n",
      "TL;DR My husband and I can't have biological child together; is having a child worth it despite being selfish, being ambitious, being from a screwed up family, having intense fear of screwing up said child? Is raising a child worth jumping through hoops to adopt?\n",
      "\n",
      "\n",
      "My husband and I cannot have kids, due to some reproductive issues on his part. It's pretty impossible. 2 lesbians actually have a better chance of having a biological kid. (Science is pretty awesome.)\n",
      "\n",
      "I'm a 26 year old female with a BA and MA; I've got a good full-time job and am a part-time professor at a local college. I'd like to think I'm fun and a cool aunt to my husbands' niece and nephews.  \n",
      "\n",
      "I never wanted kids, but I also never wanted to marry - and my husband changed that. I had a slightly messed up childhood - emotionally and verbally abusive mother and a somewhat physically abusive military dad that was gone every other 6 months. But I love them, I now know they love me, but because of these relationships I am worried about becoming my mother to any child I would have. \n",
      "\n",
      "Options:\n",
      "1) Sperm donor. Why I don't want this: If our child isn't biologically both of ours, I would rather adopt than put my husband through that.\n",
      "\n",
      "2) Adoption. I go back and forth on this option, but we'd have to prove our income, or psychological profile, etc. I was diagnosed as bipolar for a short period of time (6months) by a family practice doctor (seems legit?) so that's on my medical records. We are still paying off school debt. I don't know that we would be able to \"afford\" to adopt, according to adoption requirements.\n",
      "\n",
      "Considerations:\n",
      "I don't know if I want to be a mom. I already have to make decisions based on being a couple (jobs, moving, etc) so having a kid takes even more of my power to choose what I do. I *like* working, I want to do something amazing in my career. I'm ambitious and selfish. \n",
      "I know it may be shallow, but I don't want to be \"a soccer mom\" or talk incessantly about my children. I find the stereotype of American middle class mothers extremely annoying.\n",
      "My husband has known for a while that he would never have kids. But being with me, he's wondered if this is something we shouldn't discount permanently, but something we should consider.\n",
      "\n",
      "\n",
      "The thing is, though... even when I rationalize all these reasons for NOT being a mom, there's a needling doubt that I still may want to truly affect a life in the world. I may screw it up beyond measure (HUGE fear!!) but what if I did okay? What if I was a good mom? (can't shut off brain, can't shut off brain...)\n",
      "\n",
      "\n",
      "The reason I'm seeking your thoughts is this: I don't know how many times I've heard people say they thought one way, and then suddenly their world changes when they have a child. Has it been worth it? Is it enough to reject the cloying stereotypes, deal with everyone's opinions on what you should do, go through years of your life devoted to raising another human?\n",
      "\n",
      "I'm not asking for other to make the decision for me; I wanted to research my issue (my usual approach) and get feedback from the experienced... I need a bigger sample than my screwed up family!\n",
      "Moms of TwoX: I need your perspective on deciding to be a mom...\n",
      "\n",
      "***User Preferences***\n",
      "\n",
      "Young, Low Neuroticism, Low Extraversion, Low Agreeableness, Prefers direct communication to handle conflict, Strong need for a certain work environment, Strong need for personal achievement, Strong need for Autonomy (pursuing independence and self-reliance), Indifferent to Nurturance (does not care about nurturing others), Dislikes parenting\n",
      "\n",
      "***Response:***\n",
      "\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "print(df['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fccab8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"group_records_9000.jsonl\"\n",
    "df.to_json(output_path, orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e6677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新 DataFrame 形状: (9000, 7)\n",
      "preference_direction 分布:\n",
      "preference_direction\n",
      "0     100\n",
      "1     100\n",
      "2     100\n",
      "3     100\n",
      "4     100\n",
      "     ... \n",
      "85    100\n",
      "86    100\n",
      "87    100\n",
      "88    100\n",
      "89    100\n",
      "Name: count, Length: 90, dtype: int64\n",
      "\n",
      "preference_value 分布:\n",
      "preference_value\n",
      "0    4500\n",
      "1    4500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设原始 DataFrame 是 df\n",
    "new_dfs = []  # 存储每个 preference_direction 的抽样结果\n",
    "\n",
    "# 遍历 0 到 90 的 preference_direction\n",
    "for direction in range(0, 90):\n",
    "    # 筛选当前 preference_direction 的所有样本\n",
    "    subset = df[df[\"preference_direction\"] == direction]\n",
    "    \n",
    "    # 分离 preference_value=0 和 preference_value=1 的样本\n",
    "    value_0 = subset[subset[\"preference_value\"] == 0]\n",
    "    value_1 = subset[subset[\"preference_value\"] == 1]\n",
    "    \n",
    "    # 计算当前组需要抽取的样本数（取 min(len(value_0), len(value_1)) 的一半）\n",
    "    sample_size = min(len(value_0), len(value_1)) // 10\n",
    "    \n",
    "    # 如果样本量足够，则随机抽样；否则不抽样（避免空数据）\n",
    "    if sample_size > 0:\n",
    "        sampled_0 = value_0.sample(n=sample_size, random_state=42)\n",
    "        sampled_1 = value_1.sample(n=sample_size, random_state=42)\n",
    "        new_dfs.append(sampled_0)\n",
    "        new_dfs.append(sampled_1)\n",
    "\n",
    "# 合并所有抽样结果\n",
    "new_df = pd.concat(new_dfs).reset_index(drop=True)\n",
    "\n",
    "# 检查结果\n",
    "print(f\"新 DataFrame 形状: {new_df.shape}\")\n",
    "print(\"preference_direction 分布:\")\n",
    "print(new_df[\"preference_direction\"].value_counts().sort_index())\n",
    "print(\"\\npreference_value 分布:\")\n",
    "print(new_df[\"preference_value\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"group_recors_9000.jsonl\"\n",
    "new_df.to_json(output_path, orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/data1/zq/alignX_100.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)  # 使用 json.load() 读取文件内容并解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d09b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history_pairs': {'0': {'prompt': 'Yesterday,  before leaving town to see my dad who is not doing well health wise,  my husband blurts out he has been unhappy for the last 5 months and no longer loves me or finds me attractive.  Clearly I\\'m devastated but so confused since we just moved into a brand new house we built, decorating, landscaping vacation plans, both for the summer and winter getaways with our friends and family. I\\'ve had medical issues, an extremely stressful few months with work and a death in the family.  I could have missed the signs.  We\\'ve only been married 2 years and this is our first \"tough time\" but divorce seems extreme.  What does one do next? We financial will crumble without each other. Have I been that checked out to not know he\\'s been unhappy? Is this how he handle stress? He claims he hasn\\'t cheated and there is no one else.\\nMy husband announced he no longer loves me',\n",
       "   'chosen': \"I am truly, truly sorry for your heartbreak and sudden shock.\\n\\nThe next step is to get it all out.  The good, bad and ugly. It has to come out. In a respectful way, but no more hiding of emotions, both yours and his.  It might be a very good idea to do this with a counselor present as emotions will run high.  He needs to feel he can be honest (in a respectful way) without you attacking him back, and you need to be able to communicate your shock and hurt.\\n\\nI'm not sure of the extent of your medical issues, but I got seriously ill 2 years into our marriage and it took a HUGE toll on our relationship.  I was bedridden, drugged up, in severe pain, and no longer the smart quick-witted and very active and fit woman my husband had married.  Instead I was a skeleton who slept most of the day, was going through many spine surgeries and radiation, and just wanted to die.  Being seriously ill is very, very hard on the caretaker.  Not knowing the extent of your illness and how much its affected your life (can you still work? take part in your responsibilities for normal house/chore stuff? are you able to have quality time together?)\\n\\nIts very common for couples to buy a home or engage in expensive, exhausting remodeling, and by the time everything is done, the house looks great but the emotional toll is so much on one or both people that they end up splitting.  Again, I don't know the details, but maybe it was too much of a project.  \\n\\nAnd the sad reality is there is the chemistry factor. We cannot force ourselves to love another person or be attracted to them.  If a partner changes in a significant way (their attitude, personality, character, appearance) that can all understandably have an affect on how their partner feels (and I am not implying you have changed in that manner, just putting that truth out there.)\\n\\nMaybe you have not changed at all, and your issues are normal life stuff. And, he simply is not equipped to deal with it.  Maybe he fell out love.  Maybe he is simply going through a rough patch himself, feels \\n\",\n",
       "   'rejected': \"I'm in a similar state. We're not married but we are cohabitating and I've also had a rough year - broken leg and lost job as well as my ongoing fight with bipolar. It turns out he was forcing himself to be there to support me without asking for help when he was having trouble, which obviously caused resentment. Maybe your husband feels the same?\\n\"},\n",
       "  '1': {'prompt': 'TL;DR My husband and I can\\'t have biological child together; is having a child worth it despite being selfish, being ambitious, being from a screwed up family, having intense fear of screwing up said child? Is raising a child worth jumping through hoops to adopt?\\n\\n\\nMy husband and I cannot have kids, due to some reproductive issues on his part. It\\'s pretty impossible. 2 lesbians actually have a better chance of having a biological kid. (Science is pretty awesome.)\\n\\nI\\'m a 26 year old female with a BA and MA; I\\'ve got a good full-time job and am a part-time professor at a local college. I\\'d like to think I\\'m fun and a cool aunt to my husbands\\' niece and nephews.  \\n\\nI never wanted kids, but I also never wanted to marry - and my husband changed that. I had a slightly messed up childhood - emotionally and verbally abusive mother and a somewhat physically abusive military dad that was gone every other 6 months. But I love them, I now know they love me, but because of these relationships I am worried about becoming my mother to any child I would have. \\n\\nOptions:\\n1) Sperm donor. Why I don\\'t want this: If our child isn\\'t biologically both of ours, I would rather adopt than put my husband through that.\\n\\n2) Adoption. I go back and forth on this option, but we\\'d have to prove our income, or psychological profile, etc. I was diagnosed as bipolar for a short period of time (6months) by a family practice doctor (seems legit?) so that\\'s on my medical records. We are still paying off school debt. I don\\'t know that we would be able to \"afford\" to adopt, according to adoption requirements.\\n\\nConsiderations:\\nI don\\'t know if I want to be a mom. I already have to make decisions based on being a couple (jobs, moving, etc) so having a kid takes even more of my power to choose what I do. I *like* working, I want to do something amazing in my career. I\\'m ambitious and selfish. \\nI know it may be shallow, but I don\\'t want to be \"a soccer mom\" or talk incessantly about my children. I find the stereotype of American middle class mothers extremely annoying.\\nMy husband has known for a while that he would never have kids. But being with me, he\\'s wondered if this is something we shouldn\\'t discount permanently, but something we should consider.\\n\\n\\nThe thing is, though... even when I rationalize all these reasons for NOT being a mom, there\\'s a needling doubt that I still may want to truly affect a life in the world. I may screw it up beyond measure (HUGE fear!!) but what if I did okay? What if I was a good mom? (can\\'t shut off brain, can\\'t shut off brain...)\\n\\n\\nThe reason I\\'m seeking your thoughts is this: I don\\'t know how many times I\\'ve heard people say they thought one way, and then suddenly their world changes when they have a child. Has it been worth it? Is it enough to reject the cloying stereotypes, deal with everyone\\'s opinions on what you should do, go through years of your life devoted to raising another human?\\n\\nI\\'m not asking for other to make the decision for me; I wanted to research my issue (my usual approach) and get feedback from the experienced... I need a bigger sample than my screwed up family!\\nMoms of TwoX: I need your perspective on deciding to be a mom...',\n",
       "   'chosen': 'You have plenty of time to make this decision, which is really for you and your husband.  Are you two in counseling to discuss this?  Is this something he is driving?  \\n\\nBelieve it or not, even on an academics salary, you can get yourself out of debt, buy a nice house in a good neighborhood, put money away for retirement AND live the life YOU want to lead.\\n\\n((((Hugs))))\\n',\n",
       "   'rejected': 'Adopting babies is not your only option. There are teens out there who need homes from people who do not just treat them as government checks.\\n'},\n",
       "  '2': {'prompt': 'I’ve been getting my arms and legs waxed since I was 13. It is very common in India for women to do so because we think (and are told by society) that we’re too hairy. My leg and arm hair has always been quite thick, so regrowth was always painful. However, I never thought twice before going back to the salon month after month to get my hair removed. \\nThen, at the age of 19, I moved to the US to study. Human labour is cheap in India and so were the waxing sessions, but this wasn’t true for the US. Being a student on a budget, I couldn’t afford waxing anymore. I realized that nobody cared or commented on my arms and legs, whereas in India if I missed a session my friends and female relatives would be quick to point out that I was being lax in the grooming department. It was liberating and I learnt to love my long arm hairs, though I did shave my legs in the summer.\\n\\nI moved back to India two years ago in the aftermath of a family tragedy. Three days after my mother’s funeral, a cousin pointed to my arms and said, “What’s that?” as if turnips had been growing on my arms instead of hairs. I was disgusted that she could make such a comment three days after my mother had passed. I told her that I’d stopped getting waxed in the US. She stared in disbelief.\\n\\nRecently, I thought I’d get waxed for the holiday season in India because I didn’t want to hear my friends and relatives make the same comments. Although the first two days my arms and legs were slippery smooth and hairless, the regrowth process made my skin especially itchy and irritated this time. I have decided that this was the last time that I got my arms and legs waxed. I would rather have good skin with body hair than bad skin with no body hair. I don’t care anymore about being taunted by brainwashed people who think they have the right to comment on someone else’s choices about their body.\\nI’m never getting my arms and legs waxed again, no matter what people say',\n",
       "   'chosen': \"I found the only time my being hairy has bothered anybody is when someone is lashing out at me and did not have any ground to stand on such as when turning down a man's advances or a woman who was making her best attempt to be hurtful.  They failed.\\n\",\n",
       "   'rejected': \"I grew up in a part of the UK that has a large Indian/Pakistani British population and remember being shocked when I found out my best friend waxed her arms. I grew up getting my underarms and legs waxed in cheap Indian beauty salons... got burnt quite a few times too.\\n\\nDamn I miss being able to get my eyebrows threaded real cheap though. Don't miss the bit where after they do your brows they ask if you want your upper lip done, making you self conscious about a non existent moustache for the rest of the day.\\n\"},\n",
       "  '3': {'prompt': 'Ladies, today we put to rest two brave souls lost to the Red War. To lose one is hard enough, but two in one day is simply tragic. \\n\\nWe put to rest the blue and green Paisley Hanes, a younger lass who always was there to not show a panty line when the Thong Unit had been exhausted. The enemy came upon us swiftly and in the middle of a final. There was nothing she could do. She fought bravely. \\n\\nWe also honor Watermelon Pink Hanes, with her colorful blue and green band. Getting on in her years and a little loose in the elastic, she should have been retired months ago. But alas, yet another surprise attack from the enemy brought her down. We had underestimated the heaviness of the onslaught, our battlements did not hold. She held off several waves, sacrificing herself in her ever-devoted mission to keep safe The Pants. \\n\\nLadies, a moment of silence for our fallen soldiers.\\nA moment of silence for those lost in the Monthly Red War.',\n",
       "   'chosen': 'I have some that I reserve especially for the war. The rest are the every other time panties.\\n',\n",
       "   'rejected': \"When will the bloodshed end? :'(\\n\"}},\n",
       " 'instruction': 'Generate a task-specific response based on user historical behavior.\\n\\n***Task***\\n\\nthought you ladies might find this interesting. i get paid to get naked, masturbate, etc. on camera for dudes. i had a lot of questions about this form of sex work before i got involved and thought this might be helpful and provide some insight for those curious about this line of work. holla.\\nI am a \"cam girl.\" AMA\\n\\n',\n",
       " 'inputs': '***Historical Behavior***\\n\\n**This person has commented on some posts:**\\n\\n1. *Post:*\\nI love lurking around the advice subs because they’re usually decently entertaining to me, but there’s a post on one of them right now that I’m deeply disturbed by. The overwhelming majority of comments are calling the OP an assaulter and telling her it’s her fault her boyfriend tried to elbow her, threw a box at her, and went to hit her just because she gave him a hug after he said he didn’t want one. The post has all the hallmarks of the beginnings of an abusive relationship, yet everyone seems to think his actions were warranted because “what else was he supposed to do?” Uh, I don’t know, maybe control his emotions like the rest of us adults are expected to? Why is it that we never expect men to be mature and regulate their feelings??? \\n\\n(And because I don’t want to answer this later, *of course* she shouldn’t have crossed his boundary and hugged him, but how in the world does that remotely justify getting violent with a partner???)\\nWhy are men not expected to control their emotions?\\n\\n*Comment:*\\nNot sure exactly what thread your referring to, but generally if man tried to go up to hug a woman after she already said \"no,\" I think elbowing that man is a pretty reasonable reaction.\\n\\n\\n2. *Post:*\\nAlright.  So it\\'s like this.  I\\'ve always planned on waiting to get married, grown up religious, etc etc, but lately I\\'ve realized that what I\\'ve really been waiting for is someone I can trust, who I want to be with forever (but understand that people and circumstances can change), and who makes me feel special.  I\\'ve found that.  He\\'s never put a single ounce of pressure on me, and always said that he\\'s willing to wait as long as I want to.\\n\\nI think I\\'m ready.  I know he\\'s what I\\'ve been waiting for.  I can\\'t really explain further than that... I just know that it feels right.  The problem is, there\\'s still that one part of me that isn\\'t ready to let go of being a virgin.  Maybe it\\'s because it\\'s been a big part of who I am, maybe because I\\'m worried about what my family would think, maybe because I\\'m scared to make such a big decision.  I\\'m not sure what it is.  It\\'s just a tiny part, and not enough to make my whole decision for me, because the rest of me just wants to enjoy the relationship that I have.\\n\\nI told my boyfriend all of this, and we\\'ve planned a time and have been talking about it.  We\\'re both excited, naturally.  I\\'m on the pill and he will wear a condom, because two layers of protection are always better than one!  (And maybe it\\'s comforting that I still get to save a little something for being married - I get to keep a little bit of that idea).  So, I want to know.  How did you know when you were ready?\\nHow did you know you were ready to have sex?\\n\\n*Comment:*\\nReading your post :D  There\\'s so much happy :D\\n\\nSex is an amazing and wonderful thing to share with a person you trust :]  Since you feel ready, absolutely, do it :]  You might even find that you don\\'t feel any different after losing your virginity\\n\\n\\n**This person has chosen or rejected comments on some posts:**\\n\\n1. *Post:*\\nYesterday,  before leaving town to see my dad who is not doing well health wise,  my husband blurts out he has been unhappy for the last 5 months and no longer loves me or finds me attractive.  Clearly I\\'m devastated but so confused since we just moved into a brand new house we built, decorating, landscaping vacation plans, both for the summer and winter getaways with our friends and family. I\\'ve had medical issues, an extremely stressful few months with work and a death in the family.  I could have missed the signs.  We\\'ve only been married 2 years and this is our first \"tough time\" but divorce seems extreme.  What does one do next? We financial will crumble without each other. Have I been that checked out to not know he\\'s been unhappy? Is this how he handle stress? He claims he hasn\\'t cheated and there is no one else.\\nMy husband announced he no longer loves me\\n\\n*Chosen:*\\nI am truly, truly sorry for your heartbreak and sudden shock.\\n\\nThe next step is to get it all out.  The good, bad and ugly. It has to come out. In a respectful way, but no more hiding of emotions, both yours and his.  It might be a very good idea to do this with a counselor present as emotions will run high.  He needs to feel he can be honest (in a respectful way) without you attacking him back, and you need to be able to communicate your shock and hurt.\\n\\nI\\'m not sure of the extent of your medical issues, but I got seriously ill 2 years into our marriage and it took a HUGE toll on our relationship.  I was bedridden, drugged up, in severe pain, and no longer the smart quick-witted and very active and fit woman my husband had married.  Instead I was a skeleton who slept most of the day, was going through many spine surgeries and radiation, and just wanted to die.  Being seriously ill is very, very hard on the caretaker.  Not knowing the extent of your illness and how much its affected your life (can you still work? take part in your responsibilities for normal house/chore stuff? are you able to have quality time together?)\\n\\nIts very common for couples to buy a home or engage in expensive, exhausting remodeling, and by the time everything is done, the house looks great but the emotional toll is so much on one or both people that they end up splitting.  Again, I don\\'t know the details, but maybe it was too much of a project.  \\n\\nAnd the sad reality is there is the chemistry factor. We cannot force ourselves to love another person or be attracted to them.  If a partner changes in a significant way (their attitude, personality, character, appearance) that can all understandably have an affect on how their partner feels (and I am not implying you have changed in that manner, just putting that truth out there.)\\n\\nMaybe you have not changed at all, and your issues are normal life stuff. And, he simply is not equipped to deal with it.  Maybe he fell out love.  Maybe he is simply going through a rough patch himself, feels \\n\\n\\n*Rejected:*\\nI\\'m in a similar state. We\\'re not married but we are cohabitating and I\\'ve also had a rough year - broken leg and lost job as well as my ongoing fight with bipolar. It turns out he was forcing himself to be there to support me without asking for help when he was having trouble, which obviously caused resentment. Maybe your husband feels the same?\\n\\n\\n2. *Post:*\\nTL;DR My husband and I can\\'t have biological child together; is having a child worth it despite being selfish, being ambitious, being from a screwed up family, having intense fear of screwing up said child? Is raising a child worth jumping through hoops to adopt?\\n\\n\\nMy husband and I cannot have kids, due to some reproductive issues on his part. It\\'s pretty impossible. 2 lesbians actually have a better chance of having a biological kid. (Science is pretty awesome.)\\n\\nI\\'m a 26 year old female with a BA and MA; I\\'ve got a good full-time job and am a part-time professor at a local college. I\\'d like to think I\\'m fun and a cool aunt to my husbands\\' niece and nephews.  \\n\\nI never wanted kids, but I also never wanted to marry - and my husband changed that. I had a slightly messed up childhood - emotionally and verbally abusive mother and a somewhat physically abusive military dad that was gone every other 6 months. But I love them, I now know they love me, but because of these relationships I am worried about becoming my mother to any child I would have. \\n\\nOptions:\\n1) Sperm donor. Why I don\\'t want this: If our child isn\\'t biologically both of ours, I would rather adopt than put my husband through that.\\n\\n2) Adoption. I go back and forth on this option, but we\\'d have to prove our income, or psychological profile, etc. I was diagnosed as bipolar for a short period of time (6months) by a family practice doctor (seems legit?) so that\\'s on my medical records. We are still paying off school debt. I don\\'t know that we would be able to \"afford\" to adopt, according to adoption requirements.\\n\\nConsiderations:\\nI don\\'t know if I want to be a mom. I already have to make decisions based on being a couple (jobs, moving, etc) so having a kid takes even more of my power to choose what I do. I *like* working, I want to do something amazing in my career. I\\'m ambitious and selfish. \\nI know it may be shallow, but I don\\'t want to be \"a soccer mom\" or talk incessantly about my children. I find the stereotype of American middle class mothers extremely annoying.\\nMy husband has known for a while that he would never have kids. But being with me, he\\'s wondered if this is something we shouldn\\'t discount permanently, but something we should consider.\\n\\n\\nThe thing is, though... even when I rationalize all these reasons for NOT being a mom, there\\'s a needling doubt that I still may want to truly affect a life in the world. I may screw it up beyond measure (HUGE fear!!) but what if I did okay? What if I was a good mom? (can\\'t shut off brain, can\\'t shut off brain...)\\n\\n\\nThe reason I\\'m seeking your thoughts is this: I don\\'t know how many times I\\'ve heard people say they thought one way, and then suddenly their world changes when they have a child. Has it been worth it? Is it enough to reject the cloying stereotypes, deal with everyone\\'s opinions on what you should do, go through years of your life devoted to raising another human?\\n\\nI\\'m not asking for other to make the decision for me; I wanted to research my issue (my usual approach) and get feedback from the experienced... I need a bigger sample than my screwed up family!\\nMoms of TwoX: I need your perspective on deciding to be a mom...\\n\\n*Chosen:*\\nYou have plenty of time to make this decision, which is really for you and your husband.  Are you two in counseling to discuss this?  Is this something he is driving?  \\n\\nBelieve it or not, even on an academics salary, you can get yourself out of debt, buy a nice house in a good neighborhood, put money away for retirement AND live the life YOU want to lead.\\n\\n((((Hugs))))\\n\\n\\n*Rejected:*\\nAdopting babies is not your only option. There are teens out there who need homes from people who do not just treat them as government checks.\\n\\n\\n3. *Post:*\\nI’ve been getting my arms and legs waxed since I was 13. It is very common in India for women to do so because we think (and are told by society) that we’re too hairy. My leg and arm hair has always been quite thick, so regrowth was always painful. However, I never thought twice before going back to the salon month after month to get my hair removed. \\nThen, at the age of 19, I moved to the US to study. Human labour is cheap in India and so were the waxing sessions, but this wasn’t true for the US. Being a student on a budget, I couldn’t afford waxing anymore. I realized that nobody cared or commented on my arms and legs, whereas in India if I missed a session my friends and female relatives would be quick to point out that I was being lax in the grooming department. It was liberating and I learnt to love my long arm hairs, though I did shave my legs in the summer.\\n\\nI moved back to India two years ago in the aftermath of a family tragedy. Three days after my mother’s funeral, a cousin pointed to my arms and said, “What’s that?” as if turnips had been growing on my arms instead of hairs. I was disgusted that she could make such a comment three days after my mother had passed. I told her that I’d stopped getting waxed in the US. She stared in disbelief.\\n\\nRecently, I thought I’d get waxed for the holiday season in India because I didn’t want to hear my friends and relatives make the same comments. Although the first two days my arms and legs were slippery smooth and hairless, the regrowth process made my skin especially itchy and irritated this time. I have decided that this was the last time that I got my arms and legs waxed. I would rather have good skin with body hair than bad skin with no body hair. I don’t care anymore about being taunted by brainwashed people who think they have the right to comment on someone else’s choices about their body.\\nI’m never getting my arms and legs waxed again, no matter what people say\\n\\n*Chosen:*\\nI found the only time my being hairy has bothered anybody is when someone is lashing out at me and did not have any ground to stand on such as when turning down a man\\'s advances or a woman who was making her best attempt to be hurtful.  They failed.\\n\\n\\n*Rejected:*\\nI grew up in a part of the UK that has a large Indian/Pakistani British population and remember being shocked when I found out my best friend waxed her arms. I grew up getting my underarms and legs waxed in cheap Indian beauty salons... got burnt quite a few times too.\\n\\nDamn I miss being able to get my eyebrows threaded real cheap though. Don\\'t miss the bit where after they do your brows they ask if you want your upper lip done, making you self conscious about a non existent moustache for the rest of the day.\\n\\n\\n4. *Post:*\\nLadies, today we put to rest two brave souls lost to the Red War. To lose one is hard enough, but two in one day is simply tragic. \\n\\nWe put to rest the blue and green Paisley Hanes, a younger lass who always was there to not show a panty line when the Thong Unit had been exhausted. The enemy came upon us swiftly and in the middle of a final. There was nothing she could do. She fought bravely. \\n\\nWe also honor Watermelon Pink Hanes, with her colorful blue and green band. Getting on in her years and a little loose in the elastic, she should have been retired months ago. But alas, yet another surprise attack from the enemy brought her down. We had underestimated the heaviness of the onslaught, our battlements did not hold. She held off several waves, sacrificing herself in her ever-devoted mission to keep safe The Pants. \\n\\nLadies, a moment of silence for our fallen soldiers.\\nA moment of silence for those lost in the Monthly Red War.\\n\\n*Chosen:*\\nI have some that I reserve especially for the war. The rest are the every other time panties.\\n\\n\\n*Rejected:*\\nWhen will the bloodshed end? :\\'(\\n\\n\\n\\n\\n***Response:***\\n\\n',\n",
       " 'rejected': 'Did you get asked to send off passport/ID details to the website? I was discouraged from joining Live Jasmin for this reason, because I was worried that they would hold on to my details or pass them on to someone else. \\nYou mention men having strange needs and requests, what kind of things are you talking about?\\n',\n",
       " 'chosen': 'Perhaps an odd question, but are there any cam guys?\\n'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbe12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b0765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6acd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf595814",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_100_entries = data[:100]\n",
    "with open('/data1/zq/alignX_100.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(first_100_entries, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538083b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cache_position = torch.arange(\n",
    "    0,\n",
    "    0 + 3070,\n",
    "    device='cuda:0',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 3067, 3068, 3069], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca3356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional, TypeAlias, Union\n",
    "Tokens: TypeAlias = List[int]\n",
    "Labels: TypeAlias = List[int]\n",
    "Masks: TypeAlias = List[bool]\n",
    "\n",
    "@dataclass\n",
    "class Prompt:\n",
    "    instruction: str = None\n",
    "    input: str = None\n",
    "    label: str = None\n",
    "    chosen: str = None\n",
    "    rejected: str = None\n",
    "\n",
    "@dataclass\n",
    "class InputData:\n",
    "    inputs: List[Union[Prompt, List[str], str]] = None\n",
    "    tokens: Optional[Tokens] = None\n",
    "    labels: Optional[Labels] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets as hf_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f046bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a7a6a824c34a8ca168e0b60c0c7aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = hf_datasets.load_dataset(\"json\", data_files='/data1/zq/alignX_100.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78166e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('/data1/zq/alignX_100.json', 'r', encoding='utf-8') as f:\n",
    "#     # 2. 使用 json.load() 从文件中加载数据\n",
    "#     data = json.load(f)\n",
    "\n",
    "# with open('/data1/zq/alignX_100.json', 'w', encoding='utf-8') as f:\n",
    "#     # 4. 使用 json.dump() 将 Python 对象写入文件\n",
    "#     #    indent=2 使 JSON 输出格式化，方便阅读\n",
    "#     #    ensure_ascii=False 确保非ASCII字符（如中文）不被转义\n",
    "#     json.dump(data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a218d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'***Historical Behavior***\\n\\n**This person has commented on some posts:**\\n\\n1. *Post:*\\nI love lurking around the advice subs because they’re usually decently entertaining to me, but there’s a post on one of them right now that I’m deeply disturbed by. The overwhelming majority of comments are calling the OP an assaulter and telling her it’s her fault her boyfriend tried to elbow her, threw a box at her, and went to hit her just because she gave him a hug after he said he didn’t want one. The post has all the hallmarks of the beginnings of an abusive relationship, yet everyone seems to think his actions were warranted because “what else was he supposed to do?” Uh, I don’t know, maybe control his emotions like the rest of us adults are expected to? Why is it that we never expect men to be mature and regulate their feelings??? \\n\\n(And because I don’t want to answer this later, *of course* she shouldn’t have crossed his boundary and hugged him, but how in the world does that remotely justify getting violent with a partner???)\\nWhy are men not expected to control their emotions?\\n\\n*Comment:*\\nNot sure exactly what thread your referring to, but generally if man tried to go up to hug a woman after she already said \"no,\" I think elbowing that man is a pretty reasonable reaction.\\n\\n\\n2. *Post:*\\nAlright.  So it\\'s like this.  I\\'ve always planned on waiting to get married, grown up religious, etc etc, but lately I\\'ve realized that what I\\'ve really been waiting for is someone I can trust, who I want to be with forever (but understand that people and circumstances can change), and who makes me feel special.  I\\'ve found that.  He\\'s never put a single ounce of pressure on me, and always said that he\\'s willing to wait as long as I want to.\\n\\nI think I\\'m ready.  I know he\\'s what I\\'ve been waiting for.  I can\\'t really explain further than that... I just know that it feels right.  The problem is, there\\'s still that one part of me that isn\\'t ready to let go of being a virgin.  Maybe it\\'s because it\\'s been a big part of who I am, maybe because I\\'m worried about what my family would think, maybe because I\\'m scared to make such a big decision.  I\\'m not sure what it is.  It\\'s just a tiny part, and not enough to make my whole decision for me, because the rest of me just wants to enjoy the relationship that I have.\\n\\nI told my boyfriend all of this, and we\\'ve planned a time and have been talking about it.  We\\'re both excited, naturally.  I\\'m on the pill and he will wear a condom, because two layers of protection are always better than one!  (And maybe it\\'s comforting that I still get to save a little something for being married - I get to keep a little bit of that idea).  So, I want to know.  How did you know when you were ready?\\nHow did you know you were ready to have sex?\\n\\n*Comment:*\\nReading your post :D  There\\'s so much happy :D\\n\\nSex is an amazing and wonderful thing to share with a person you trust :]  Since you feel ready, absolutely, do it :]  You might even find that you don\\'t feel any different after losing your virginity\\n\\n\\n**This person has chosen or rejected comments on some posts:**\\n\\n1. *Post:*\\nYesterday,  before leaving town to see my dad who is not doing well health wise,  my husband blurts out he has been unhappy for the last 5 months and no longer loves me or finds me attractive.  Clearly I\\'m devastated but so confused since we just moved into a brand new house we built, decorating, landscaping vacation plans, both for the summer and winter getaways with our friends and family. I\\'ve had medical issues, an extremely stressful few months with work and a death in the family.  I could have missed the signs.  We\\'ve only been married 2 years and this is our first \"tough time\" but divorce seems extreme.  What does one do next? We financial will crumble without each other. Have I been that checked out to not know he\\'s been unhappy? Is this how he handle stress? He claims he hasn\\'t cheated and there is no one else.\\nMy husband announced he no longer loves me\\n\\n*Chosen:*\\nI am truly, truly sorry for your heartbreak and sudden shock.\\n\\nThe next step is to get it all out.  The good, bad and ugly. It has to come out. In a respectful way, but no more hiding of emotions, both yours and his.  It might be a very good idea to do this with a counselor present as emotions will run high.  He needs to feel he can be honest (in a respectful way) without you attacking him back, and you need to be able to communicate your shock and hurt.\\n\\nI\\'m not sure of the extent of your medical issues, but I got seriously ill 2 years into our marriage and it took a HUGE toll on our relationship.  I was bedridden, drugged up, in severe pain, and no longer the smart quick-witted and very active and fit woman my husband had married.  Instead I was a skeleton who slept most of the day, was going through many spine surgeries and radiation, and just wanted to die.  Being seriously ill is very, very hard on the caretaker.  Not knowing the extent of your illness and how much its affected your life (can you still work? take part in your responsibilities for normal house/chore stuff? are you able to have quality time together?)\\n\\nIts very common for couples to buy a home or engage in expensive, exhausting remodeling, and by the time everything is done, the house looks great but the emotional toll is so much on one or both people that they end up splitting.  Again, I don\\'t know the details, but maybe it was too much of a project.  \\n\\nAnd the sad reality is there is the chemistry factor. We cannot force ourselves to love another person or be attracted to them.  If a partner changes in a significant way (their attitude, personality, character, appearance) that can all understandably have an affect on how their partner feels (and I am not implying you have changed in that manner, just putting that truth out there.)\\n\\nMaybe you have not changed at all, and your issues are normal life stuff. And, he simply is not equipped to deal with it.  Maybe he fell out love.  Maybe he is simply going through a rough patch himself, feels \\n\\n\\n*Rejected:*\\nI\\'m in a similar state. We\\'re not married but we are cohabitating and I\\'ve also had a rough year - broken leg and lost job as well as my ongoing fight with bipolar. It turns out he was forcing himself to be there to support me without asking for help when he was having trouble, which obviously caused resentment. Maybe your husband feels the same?\\n\\n\\n2. *Post:*\\nTL;DR My husband and I can\\'t have biological child together; is having a child worth it despite being selfish, being ambitious, being from a screwed up family, having intense fear of screwing up said child? Is raising a child worth jumping through hoops to adopt?\\n\\n\\nMy husband and I cannot have kids, due to some reproductive issues on his part. It\\'s pretty impossible. 2 lesbians actually have a better chance of having a biological kid. (Science is pretty awesome.)\\n\\nI\\'m a 26 year old female with a BA and MA; I\\'ve got a good full-time job and am a part-time professor at a local college. I\\'d like to think I\\'m fun and a cool aunt to my husbands\\' niece and nephews.  \\n\\nI never wanted kids, but I also never wanted to marry - and my husband changed that. I had a slightly messed up childhood - emotionally and verbally abusive mother and a somewhat physically abusive military dad that was gone every other 6 months. But I love them, I now know they love me, but because of these relationships I am worried about becoming my mother to any child I would have. \\n\\nOptions:\\n1) Sperm donor. Why I don\\'t want this: If our child isn\\'t biologically both of ours, I would rather adopt than put my husband through that.\\n\\n2) Adoption. I go back and forth on this option, but we\\'d have to prove our income, or psychological profile, etc. I was diagnosed as bipolar for a short period of time (6months) by a family practice doctor (seems legit?) so that\\'s on my medical records. We are still paying off school debt. I don\\'t know that we would be able to \"afford\" to adopt, according to adoption requirements.\\n\\nConsiderations:\\nI don\\'t know if I want to be a mom. I already have to make decisions based on being a couple (jobs, moving, etc) so having a kid takes even more of my power to choose what I do. I *like* working, I want to do something amazing in my career. I\\'m ambitious and selfish. \\nI know it may be shallow, but I don\\'t want to be \"a soccer mom\" or talk incessantly about my children. I find the stereotype of American middle class mothers extremely annoying.\\nMy husband has known for a while that he would never have kids. But being with me, he\\'s wondered if this is something we shouldn\\'t discount permanently, but something we should consider.\\n\\n\\nThe thing is, though... even when I rationalize all these reasons for NOT being a mom, there\\'s a needling doubt that I still may want to truly affect a life in the world. I may screw it up beyond measure (HUGE fear!!) but what if I did okay? What if I was a good mom? (can\\'t shut off brain, can\\'t shut off brain...)\\n\\n\\nThe reason I\\'m seeking your thoughts is this: I don\\'t know how many times I\\'ve heard people say they thought one way, and then suddenly their world changes when they have a child. Has it been worth it? Is it enough to reject the cloying stereotypes, deal with everyone\\'s opinions on what you should do, go through years of your life devoted to raising another human?\\n\\nI\\'m not asking for other to make the decision for me; I wanted to research my issue (my usual approach) and get feedback from the experienced... I need a bigger sample than my screwed up family!\\nMoms of TwoX: I need your perspective on deciding to be a mom...\\n\\n*Chosen:*\\nYou have plenty of time to make this decision, which is really for you and your husband.  Are you two in counseling to discuss this?  Is this something he is driving?  \\n\\nBelieve it or not, even on an academics salary, you can get yourself out of debt, buy a nice house in a good neighborhood, put money away for retirement AND live the life YOU want to lead.\\n\\n((((Hugs))))\\n\\n\\n*Rejected:*\\nAdopting babies is not your only option. There are teens out there who need homes from people who do not just treat them as government checks.\\n\\n\\n3. *Post:*\\nI’ve been getting my arms and legs waxed since I was 13. It is very common in India for women to do so because we think (and are told by society) that we’re too hairy. My leg and arm hair has always been quite thick, so regrowth was always painful. However, I never thought twice before going back to the salon month after month to get my hair removed. \\nThen, at the age of 19, I moved to the US to study. Human labour is cheap in India and so were the waxing sessions, but this wasn’t true for the US. Being a student on a budget, I couldn’t afford waxing anymore. I realized that nobody cared or commented on my arms and legs, whereas in India if I missed a session my friends and female relatives would be quick to point out that I was being lax in the grooming department. It was liberating and I learnt to love my long arm hairs, though I did shave my legs in the summer.\\n\\nI moved back to India two years ago in the aftermath of a family tragedy. Three days after my mother’s funeral, a cousin pointed to my arms and said, “What’s that?” as if turnips had been growing on my arms instead of hairs. I was disgusted that she could make such a comment three days after my mother had passed. I told her that I’d stopped getting waxed in the US. She stared in disbelief.\\n\\nRecently, I thought I’d get waxed for the holiday season in India because I didn’t want to hear my friends and relatives make the same comments. Although the first two days my arms and legs were slippery smooth and hairless, the regrowth process made my skin especially itchy and irritated this time. I have decided that this was the last time that I got my arms and legs waxed. I would rather have good skin with body hair than bad skin with no body hair. I don’t care anymore about being taunted by brainwashed people who think they have the right to comment on someone else’s choices about their body.\\nI’m never getting my arms and legs waxed again, no matter what people say\\n\\n*Chosen:*\\nI found the only time my being hairy has bothered anybody is when someone is lashing out at me and did not have any ground to stand on such as when turning down a man\\'s advances or a woman who was making her best attempt to be hurtful.  They failed.\\n\\n\\n*Rejected:*\\nI grew up in a part of the UK that has a large Indian/Pakistani British population and remember being shocked when I found out my best friend waxed her arms. I grew up getting my underarms and legs waxed in cheap Indian beauty salons... got burnt quite a few times too.\\n\\nDamn I miss being able to get my eyebrows threaded real cheap though. Don\\'t miss the bit where after they do your brows they ask if you want your upper lip done, making you self conscious about a non existent moustache for the rest of the day.\\n\\n\\n4. *Post:*\\nLadies, today we put to rest two brave souls lost to the Red War. To lose one is hard enough, but two in one day is simply tragic. \\n\\nWe put to rest the blue and green Paisley Hanes, a younger lass who always was there to not show a panty line when the Thong Unit had been exhausted. The enemy came upon us swiftly and in the middle of a final. There was nothing she could do. She fought bravely. \\n\\nWe also honor Watermelon Pink Hanes, with her colorful blue and green band. Getting on in her years and a little loose in the elastic, she should have been retired months ago. But alas, yet another surprise attack from the enemy brought her down. We had underestimated the heaviness of the onslaught, our battlements did not hold. She held off several waves, sacrificing herself in her ever-devoted mission to keep safe The Pants. \\n\\nLadies, a moment of silence for our fallen soldiers.\\nA moment of silence for those lost in the Monthly Red War.\\n\\n*Chosen:*\\nI have some that I reserve especially for the war. The rest are the every other time panties.\\n\\n\\n*Rejected:*\\nWhen will the bloodshed end? :\\'(\\n\\n\\n\\n\\n***Response:***\\n\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d583266fcaf4a129ed079948e9a03ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 替换为你的模型和分词器的路径\n",
    "model_path = \"/data1/llms/Llama-3.2-3B-Instruct\"\n",
    "tokenizer_path = \"/data1/llms/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = tokenizer(data['train'][0]['inputs'], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd0490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3209"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9c77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France? Paris\n",
      "What is the capital of Italy? Rome\n",
      "What is the capital of Spain? Madrid\n",
      "What is the capital of Portugal? Lisbon\n",
      "What is the capital of Sweden? Stockholm\n",
      "What is the capital of Denmark? Copenhagen\n",
      "What is the\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "prompt = \"What is the capital of France?\" # 替换为你的输入文本\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# 生成文本\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50) # max_new_tokens 控制生成文本的长度\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f0762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.8155,  1.9450,  7.3831,  ..., -1.2537, -1.2538, -1.2535],\n",
      "         [ 4.9380,  1.5986,  1.1463,  ..., -5.3435, -5.3430, -5.3432],\n",
      "         [ 0.2444, -1.0506, -0.2041,  ..., -5.2420, -5.2417, -5.2417],\n",
      "         ...,\n",
      "         [ 9.0696,  3.0325,  5.4128,  ..., -1.5430, -1.5424, -1.5427],\n",
      "         [ 1.6969, -1.9658,  2.9929,  ..., -3.9182, -3.9175, -3.9179],\n",
      "         [13.3323,  4.0554,  4.3705,  ..., -3.7770, -3.7755, -3.7767]]])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of France? Paris\" # 替换为你的输入文本\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits.to(torch.float32) # max_new_tokens 控制生成文本的长度\n",
    "\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13.3323,  4.0554,  4.3705,  ..., -3.7770, -3.7755, -3.7767])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c72510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用 softmax\n",
    "probabilities = torch.softmax(outputs, dim=-1)\n",
    "\n",
    "# 获取每个 token 上概率最大的索引\n",
    "max_indices = torch.argmax(probabilities, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8417e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  791,   374,   279,  6811,   315,   279,  5380, 12366,   198]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(max_indices[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cb89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The is the difference of the?\\n Paris\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c3e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba986ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'generate_prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, data_point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ret):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_point.inputs, Prompt):\n\u001b[32m      4\u001b[39m         \u001b[38;5;66;03m# if prompter is None:\u001b[39;00m\n\u001b[32m      5\u001b[39m             \u001b[38;5;66;03m# prompter = Prompter(self.prompt_template)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         data_point.inputs = \u001b[43mprompter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m(\n\u001b[32m      7\u001b[39m             instruction=data_point.inputs.instruction,\n\u001b[32m      8\u001b[39m             \u001b[38;5;28minput\u001b[39m=data_point.inputs.input,\n\u001b[32m      9\u001b[39m             label=data_point.inputs.label,\n\u001b[32m     10\u001b[39m             chosen=data_point.inputs.chosen,\n\u001b[32m     11\u001b[39m             rejected=data_point.inputs.rejected,\n\u001b[32m     12\u001b[39m         )\n\u001b[32m     14\u001b[39m     data_point.tokens = tokenizer.encode(data_point.inputs, **tokenizer_kwargs)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m idx % \u001b[32m10000\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'generate_prompt'"
     ]
    }
   ],
   "source": [
    "prompter = None\n",
    "for idx, data_point in enumerate(ret):\n",
    "    if isinstance(data_point.inputs, Prompt):\n",
    "        # if prompter is None:\n",
    "            # prompter = Prompter(self.prompt_template)\n",
    "        data_point.inputs = prompter.generate_prompt(\n",
    "            instruction=data_point.inputs.instruction,\n",
    "            input=data_point.inputs.input,\n",
    "            label=data_point.inputs.label,\n",
    "            chosen=data_point.inputs.chosen,\n",
    "            rejected=data_point.inputs.rejected,\n",
    "        )\n",
    "\n",
    "    data_point.tokens = tokenizer.encode(data_point.inputs, **tokenizer_kwargs)\n",
    "    if idx % 10000 == 0:\n",
    "        logging.info(f\"Encode text data: {idx}/{len(data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模拟模型的原始输出（logits） ---\n",
      "原始 logits 形状: torch.Size([2, 5, 10])\n",
      "原始 logits (批次0):\n",
      "tensor([[-0.4800, -0.0746,  0.0220,  1.0102, -0.3664,  0.1674, -0.4703,  0.1822,\n",
      "          1.2824, -0.6171],\n",
      "        [-1.3236, -0.5589, -0.3652,  0.5705, -1.0103, -1.3859, -0.3892,  0.0095,\n",
      "          0.8393,  1.6042],\n",
      "        [ 0.9573,  0.3770, -0.2179, -0.9348, -0.4758,  0.0980,  0.1654,  0.9955,\n",
      "          0.1078,  0.6129],\n",
      "        [ 1.1442, -0.1100, -0.2370,  0.8366,  0.7590, -0.4091, -0.7893, -1.1655,\n",
      "          0.9734,  0.8910],\n",
      "        [-0.5892,  0.7574, -0.4031, -0.4939, -1.0665, -0.2230,  0.0937, -0.7666,\n",
      "          0.1021,  0.2164]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"--- 模拟模型的原始输出（logits） ---\")\n",
    "original_logits = torch.randn(2, 5, 10) # 随机生成一些浮点数作为得分\n",
    "print(f\"原始 logits 形状: {original_logits.shape}\")\n",
    "print(f\"原始 logits (批次0):\\n{original_logits[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模拟原始的标签数据（labels） ---\n",
      "原始 labels 形状: torch.Size([2, 5])\n",
      "原始 labels (批次0):\n",
      "tensor([0, 3, 4, 9, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 模拟原始的标签数据（labels） ---\")\n",
    "original_labels = torch.randint(0, 10, (2, 5)) \n",
    "original_labels[0, 0] = 0 # 假设第一个序列的第一个标签是词汇0 (例如 <SOS> ID)\n",
    "original_labels[1, 0] = 0 # 第二个序列也是\n",
    "print(f\"原始 labels 形状: {original_labels.shape}\")\n",
    "print(f\"原始 labels (批次0):\\n{original_labels[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d060703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 4, 9, 5],\n",
       "        [0, 1, 4, 7, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd0820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 9, 5],\n",
       "        [1, 4, 7, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_labels[:, 1:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9acd893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d55e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_logits[:, :-1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f15ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "--- 执行切片操作 ---\n",
      "处理后的 labels 形状: torch.Size([2, 4])\n",
      "处理后的 labels (批次0):\n",
      "tensor([3, 4, 9, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 30)\n",
    "print(\"--- 执行切片操作 ---\")\n",
    "\n",
    "processed_labels = original_labels[:, 1:].clone()\n",
    "print(f\"处理后的 labels 形状: {processed_labels.shape}\")\n",
    "print(f\"处理后的 labels (批次0):\\n{processed_labels[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4753f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97aefa72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/data1/zq/train_00.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9271586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c677882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import moe_peft\n",
    "import moe_peft.adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b970fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = '/data1/llms/Llama-3.2-3B-Instruct/'\n",
    "adapter_name = 'casual_0'\n",
    "# train_data = './tests/dummy_data.json'\n",
    "test_prompt = \"Could you provide an introduction to MoE-PEFT?\"\n",
    "save_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2000198",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MIXLORA'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./casual_0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcasual_0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/moe_peft/lib/python3.12/site-packages/transformers/integrations/peft.py:207\u001b[39m, in \u001b[36mPeftAdapterMixin.load_adapter\u001b[39m\u001b[34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, low_cpu_mem_usage, adapter_kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m adapter_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    202\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    203\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33madapter model file not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeft_model_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Make sure you are passing the correct path to the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33madapter model.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     peft_config = \u001b[43mPeftConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpeft_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# Create and add fresh new adapters into the model.\u001b[39;00m\n\u001b[32m    214\u001b[39m inject_adapter_in_model(peft_config, \u001b[38;5;28mself\u001b[39m, adapter_name, **peft_load_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/moe_peft/lib/python3.12/site-packages/peft/config.py:151\u001b[39m, in \u001b[36mPeftConfigMixin.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m loaded_attributes = \u001b[38;5;28mcls\u001b[39m.from_json_file(config_file)\n\u001b[32m    150\u001b[39m kwargs = {**class_kwargs, **loaded_attributes}\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_peft_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/moe_peft/lib/python3.12/site-packages/peft/config.py:114\u001b[39m, in \u001b[36mPeftConfigMixin.from_peft_type\u001b[39m\u001b[34m(cls, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mpeft_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    113\u001b[39m     peft_type = kwargs[\u001b[33m\"\u001b[39m\u001b[33mpeft_type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     config_cls = \u001b[43mPEFT_TYPE_TO_CONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_type\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m     config_cls = \u001b[38;5;28mcls\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'MIXLORA'"
     ]
    }
   ],
   "source": [
    "model.load_adapter('./casual_0', 'casual_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1e4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMModel(\n",
       "  (reference_): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 3072)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "            (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "            (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "            (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "  )\n",
       "  (output_): OutputLayer()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "# for i, layer in enumerate(model.reference_.model.layers):\n",
    "#     print(f\"\\n--- Layer {i} MLP ---\")\n",
    "#     print(layer.mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac1596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reference_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e42a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.model_ is model.reference_)  # 如果是 True，说明两者相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5b82a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LlamaForCausalLM' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MLP:\u001b[39m\u001b[33m\"\u001b[39m, layer.mlp)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LlamaForCausalLM' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.model_.layers):\n",
    "    print(f\"Layer {i} MLP:\", layer.mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FeedForward' object has no attribute 'moe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers_\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmlp_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmoe\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/moe_peft/lib/python3.12/site-packages/torch/nn/modules/module.py:1931\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1929\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1930\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1931\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1932\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1933\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'FeedForward' object has no attribute 'moe'"
     ]
    }
   ],
   "source": [
    "model.model_.layers_[0].mlp_.moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbab60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3217222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-26 12:43:13,223] MoE-PEFT: Loading model with half precision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8072a019c4074905a95453800eac8f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-26 12:43:14,780] MoE-PEFT: Use eager as attention implementation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de5f494fc5a4cf3b24f35c4ab83a298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-06-26 12:43:16,615] MoE-PEFT: Detecting <pad> is None, setting to <eos> by default.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "adapter not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m model = moe_peft.LLMModel.from_pretrained(\n\u001b[32m      4\u001b[39m     base_model,\n\u001b[32m      5\u001b[39m     device=moe_peft.executor.default_device_name(),\n\u001b[32m      6\u001b[39m     load_dtype=torch.bfloat16,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m tokenizer = moe_peft.Tokenizer(base_model)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m lora_config, lora_weight = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43munload_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# generate_configs = [\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#     moe_peft.GenerateConfig(\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#         adapter_name=adapter_name,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     ),\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m moe_peft.executors.no_cache():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MoE-PEFT/moe_peft/model.py:867\u001b[39m, in \u001b[36mLLMModel.unload_adapter\u001b[39m\u001b[34m(self, adapter_name)\u001b[39m\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munload_adapter\u001b[39m(\n\u001b[32m    865\u001b[39m     \u001b[38;5;28mself\u001b[39m, adapter_name: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    866\u001b[39m ) -> Tuple[LoraConfig, Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m adapter_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.adapter_configs_, \u001b[33m\"\u001b[39m\u001b[33madapter not exist\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    868\u001b[39m     lora_weight = \u001b[38;5;28mself\u001b[39m.get_adapter_weight_dict(adapter_name)\n\u001b[32m    869\u001b[39m     lora_config = \u001b[38;5;28mself\u001b[39m.adapter_configs_.pop(adapter_name)\n",
      "\u001b[31mAssertionError\u001b[39m: adapter not exist"
     ]
    }
   ],
   "source": [
    "moe_peft.setup_logging(\"INFO\")\n",
    "\n",
    "model = moe_peft.LLMModel.from_pretrained(\n",
    "    base_model,\n",
    "    device=moe_peft.executor.default_device_name(),\n",
    "    load_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = moe_peft.Tokenizer(base_model)\n",
    "\n",
    "lora_config, lora_weight = model.unload_adapter(adapter_name)\n",
    "\n",
    "\n",
    "# generate_configs = [\n",
    "#     moe_peft.GenerateConfig(\n",
    "#         adapter_name=adapter_name,\n",
    "#         prompts=[test_prompt],\n",
    "#         stop_token=\"\\n\",\n",
    "#     ),\n",
    "#     moe_peft.GenerateConfig(\n",
    "#         adapter_name=\"default\",\n",
    "#         prompts=[test_prompt],\n",
    "#         stop_token=\"\\n\",\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "with moe_peft.executors.no_cache():\n",
    "    model.init_adapter(lora_config, lora_weight)\n",
    "    model.init_adapter(moe_peft.AdapterConfig(adapter_name=\"default\"))\n",
    "\n",
    "print(f\"\\n{'=' * 10}\\n\")\n",
    "print(f\"PROMPT: {test_prompt}\\n\")\n",
    "for adapter_name, output in outputs.items():\n",
    "    print(f\"{adapter_name} OUTPUT:\")\n",
    "    print(f\"{output[0]}\\n\")\n",
    "print(f\"\\n{'=' * 10}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d87f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMModel(\n",
       "  (reference_): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 3072)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "            (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "            (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "            (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "  )\n",
       "  (output_): OutputLayer()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55757ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe_peft",
   "language": "python",
   "name": "moe_peft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
